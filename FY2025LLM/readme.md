C:\Users\litl\AppData\Local\Programs\Python\Python313\python.exe -m venv venv
python version: 3.13

0. 모델 다운로드를 위한 llama 페이지에서의 url 발급
https://www.llama.com/llama-downloads/ 

#### Requested models:
- Llama 3.3: 70B  
- Llama 3.2: 1B & 3B  
- Llama 3.2: 11B & 90B  
- Llama 3.1: 8B & 405B  

---  

1) Llama CLI 설치하기
```shell
pip install llama-stack
```
```shell
# pip install llama-stack # 이전 버전이 있었을 경우 업그레이드
```

2. 내 nvidia gpu 확인하기
```shell
nvidia-smi
```
결과
```shell
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |
| N/A   44C    P3             12W /   40W |       0MiB /   6141MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

```

3. 모델 리스트 확인하기 
```shell
llama download --model llama3-2-3b
```
결과
```shell
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓
┃ Model Descriptor(ID)                    ┃ Hugging Face Repo                                   ┃ Context Length ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩
│ Llama3.1-8B                             │ meta-llama/Llama-3.1-8B                             │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-70B                            │ meta-llama/Llama-3.1-70B                            │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-405B:bf16-mp8                  │ meta-llama/Llama-3.1-405B                           │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-405B                           │ meta-llama/Llama-3.1-405B-FP8                       │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-405B:bf16-mp16                 │ meta-llama/Llama-3.1-405B                           │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-8B-Instruct                    │ meta-llama/Llama-3.1-8B-Instruct                    │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-70B-Instruct                   │ meta-llama/Llama-3.1-70B-Instruct                   │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-405B-Instruct:bf16-mp8         │ meta-llama/Llama-3.1-405B-Instruct                  │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-405B-Instruct                  │ meta-llama/Llama-3.1-405B-Instruct-FP8              │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.1-405B-Instruct:bf16-mp16        │ meta-llama/Llama-3.1-405B-Instruct                  │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-1B                             │ meta-llama/Llama-3.2-1B                             │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-3B                             │ meta-llama/Llama-3.2-3B                             │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-11B-Vision                     │ meta-llama/Llama-3.2-11B-Vision                     │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-90B-Vision                     │ meta-llama/Llama-3.2-90B-Vision                     │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-1B-Instruct                    │ meta-llama/Llama-3.2-1B-Instruct                    │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-3B-Instruct                    │ meta-llama/Llama-3.2-3B-Instruct                    │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-1B-Instruct:int4-qlora-eo8     │ meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8     │ 8K             │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-1B-Instruct:int4-spinquant-eo8 │ meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8 │ 8K             │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-3B-Instruct:int4-qlora-eo8     │ meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8     │ 8K             │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-3B-Instruct:int4-spinquant-eo8 │ meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8 │ 8K             │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-11B-Vision-Instruct            │ meta-llama/Llama-3.2-11B-Vision-Instruct            │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.2-90B-Vision-Instruct            │ meta-llama/Llama-3.2-90B-Vision-Instruct            │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama3.3-70B-Instruct                   │ meta-llama/Llama-3.3-70B-Instruct                   │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-4-Scout-17B-16E                   │ meta-llama/Llama-4-Scout-17B-16E                    │ 256K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-4-Maverick-17B-128E               │ meta-llama/Llama-4-Maverick-17B-128E                │ 256K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-4-Scout-17B-16E-Instruct          │ meta-llama/Llama-4-Scout-17B-16E-Instruct           │ 10240K         │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-4-Maverick-17B-128E-Instruct      │ meta-llama/Llama-4-Maverick-17B-128E-Instruct       │ 1024K          │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-4-Maverick-17B-128E-Instruct:fp8  │ meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8   │ 1024K          │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-4-12B                       │ meta-llama/Llama-Guard-4-12B                        │ 8K             │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-3-11B-Vision                │ meta-llama/Llama-Guard-3-11B-Vision                 │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-3-1B:int4                   │ meta-llama/Llama-Guard-3-1B-INT4                    │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-3-1B                        │ meta-llama/Llama-Guard-3-1B                         │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-3-8B                        │ meta-llama/Llama-Guard-3-8B                         │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-3-8B:int8                   │ meta-llama/Llama-Guard-3-8B-INT8                    │ 128K           │
├─────────────────────────────────────────┼─────────────────────────────────────────────────────┼────────────────┤
│ Llama-Guard-2-8B                        │ meta-llama/Llama-Guard-2-8B                         │ 4K             │
└─────────────────────────────────────────┴─────────────────────────────────────────────────────┴────────────────┘

```


```shell
llama model list
llama model list --show-all
```

4. 모델 다운로드 하기
```shell
llama model download --source meta --model-id  MODEL_ID
llama model download --source meta --model-id Llama3.2-3B
```
위 명령어를 입력하면 다운로드를 위한 custom URL 을 입력해달라는 창이 뜬다.  
0번 에서 정보를 입력하고 임시발급된 url 을 입력한다.
```shell
# 결과
Downloading checklist.chk       ... 156 bytes
Downloading tokenizer.model     ... 2.2 MB
Downloading params.jsom         ... 220 bytes
Downloading consolidated.00.pth ... 6.4GB
```
